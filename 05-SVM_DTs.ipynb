{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical and Theoretical Exercises: SVMs, Decision Trees, and Ensemble Methods\n",
    "\n",
    "This Jupyter Notebook provides hands-on exercises for Support Vector Machines (SVMs), Decision Trees, and Ensemble Methods (Bagging & Boosting) using Python and scikit-learn.\n",
    "\n",
    "## Instructions:\n",
    "1. Follow the provided examples to understand each concept.\n",
    "2. Complete the exercises by filling in the missing code.\n",
    "3. Answer the theoretical questions to deepen your understanding.\n",
    "4. Run the code to check your answers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theoretical Exercises\n",
    "### Support Vector Machines (SVM)\n",
    "1. What is the crux of the SVM? \n",
    "2. What is a hyperplane?\n",
    "3. What is a support vector?\n",
    "4. What is the role of the kernel function in SVMs? Give some examples for kernel functions and describe when a certain function is used!\n",
    "5. Explain how we can deal with $c$-class problems when using SVMs!\n",
    "\n",
    "### Decision Trees\n",
    "1. How is a decision tree learned from data?\n",
    "2. What is entropy in the context of decision trees? How can we compute it?  \n",
    "3. What does information gain measure and how can it be computed?\n",
    "4. What are two other common impurity measures besides entropy?\n",
    "\n",
    "### Algorithm independent methods\n",
    "1. What is the main idea behind combining classifiers?\n",
    "2. What is bagging, and how does it work?  \n",
    "3. What is boosting, and how does AdaBoost work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.datasets import make_classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Implement a function that generates the necessary data! After you generated the features (X) and labels (y) split the corresponding data set into test and train data! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic dataset\n",
    "def get_dataset():\n",
    "    X, y = 'Todo'\n",
    "    return 'Todo'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Generate a data set and train a SVM! How is your SVM performing on the corresponding test data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Support Vector Machines (SVM) ---\n",
    "X_train, X_test, y_train, y_test = get_dataset()\n",
    "# Todo: Data preprocessing?\n",
    "\n",
    "# Initialize the model\n",
    "svm_model = 'Todo'\n",
    "# Train the model\n",
    "\n",
    "# Test your model\n",
    "\n",
    "# Extra: Try out different kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Train a Decision Tree with the same data set you've already generated. Compare its performance on the test set to the performance of the SVM!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Decision Trees ---\n",
    "# Initialize the model\n",
    "dt_model = 'Todo'\n",
    "# Train the model\n",
    "\n",
    "# Test your model\n",
    "\n",
    "# TODO: Experiment with different values of max_depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Try out different Bagging and Boosting approaches with different estimators. Which setup works best for you?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Bagging (Bootstrap Aggregating) ---\n",
    "# Initialize the model\n",
    "baging_model = 'Todo'\n",
    "# Train the model\n",
    "\n",
    "# Test your model\n",
    "\n",
    "# Extra: Try out different estimators\n",
    "\n",
    "# --- Boosting (AdaBoost) ---\n",
    "# Initialize the model\n",
    "adaboost_model = 'Todo'\n",
    "# Train the model\n",
    "\n",
    "# Test your model\n",
    "\n",
    "# Extra: Try out different estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lehre-oZkq39sg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
